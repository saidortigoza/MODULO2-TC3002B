# Clasificador de Desechos üóëÔ∏è

## Descripci√≥n del Proyecto

Este proyecto desarrolla un clasificador de desechos utilizando t√©cnicas de aprendizaje supervisado. El objetivo es crear un sistema que pueda identificar y clasificar diferentes tipos de residuos (vidrio, cart√≥n, org√°nicos, textiles, pl√°stico, etc.) a partir de de im√°genes. Esto puede resultar √∫til para mejorar la gesti√≥n de residuos y promover pr√°cticas de reciclaje eficientes.

## Descripci√≥n del Dataset

El dataset RealWaste proviene del repositorio de aprendizaje autom√°tico de la Universidad de California, Irvine (UCI) y se utiliza para el desarrollo de sistemas de clasificaci√≥n de desechos. El dataset se emplea para entrenar y evaluar modelos de aprendizaje supervisado con el objetivo de clasificar diferentes tipos de residuos.

El dataset contiene 4752 im√°genes de residuos etiquetados en las siguientes categor√≠as:

- Cart√≥n: 461 im√°genes

- Org√°nicos: 411 im√°genes.

- Vidrio: 420 im√°genes.

- Metal: 790 im√°genes.

- Basura Miscel√°nea: 495 im√°genes.

- Papel: 500 im√°genes.

- Pl√°stico: 921 im√°genes.

- Basura Textil: 318 im√°genes.

- Vegetaci√≥n: 436 im√°genes.

Cada categor√≠a tiene su propia carpeta, y cada carpeta contiene im√°genes en formato .jpg.

El dataset RealWaste se puede acceder y descargar desde el siguiente enlace: [RealWaste Dataset](https://archive.ics.uci.edu/dataset/908/realwaste).

## Actividades

- **Obtener, generar o aumentar un set de datos.**

El dataset utilizado para este proyecto, RealWaste, fue obtenido del [UCI Machine Learning Repository](https://archive.ics.uci.edu/dataset/908/realwaste). Contiene im√°genes clasificadas en diversas categor√≠as de desechos. Estas im√°genes se utilizar√°n para desarrollar un modelo de clasificaci√≥n.

Previo a realizar la separaci√≥n, el dataset inicial fue modificado, quedando de la siguiente manera, √∫nicamente 5 clases:

- Cardboard: 461 im√°genes.

- Food Organics: 411 im√°genes.

- Glass: 420 im√°genes.

- Metal: 474 im√°genes.

- Plastic: 489 im√°genes.

- **Hacer la separaci√≥n de los sets de prueba y entrenamiento.**

Inicialmente, el dataset no estaba dividido en sets de train y test. Por lo que se realiz√≥ una divisi√≥n del dataset inicial para dichos conjuntos, siendo dividido de la siguiente manera:

- Entrenamiento: 80%.

- Prueba: 10%.

- Validaci√≥n: 10%.

Dado que el dataset inicial cuenta con 4752 im√°genes, a las que se aplicar√°n t√©cnicas de escalamiento, utilizaremos el 70% de los datos para entrenar al modelo y poder realizar las t√©cnicas de clasificaci√≥n de desechos, de manera que los par√°metros del modelo sean ajustados y optimizados usando estos ejemplos, una vez que sea entrenado, utilizaremos un 10% para validar qu√© tan bien clasifica nuestro modelo, una vez que nuestro modelo tenga un buen rendimiento, utilizaremos el 20% restante para probarlo.

El enlace para acceder a los directorios divididos es el siguiente: [Dataset](https://drive.google.com/drive/folders/15qHsKJlguvv3mBKYhYBcgTRdKG2kicfi?usp=sharing).

- **Aplicar las t√©cnicas de escalamiento.**

Las t√©cnicas de escalamiento aplicadas fueron las siguientes:

**rescale = 1/255:** Normaliza los valores de los p√≠xeles de las im√°genes dividi√©ndolos por 255. Esto escala los valores de los p√≠xeles para que est√©n en el rango [0, 1]. Asegura que los valores de los p√≠xeles est√©n en una escala adecuada para el procesamiento por el modelo.

**rotation_range = 40:** Aplica una rotaci√≥n aleatoria a las im√°genes dentro del rango especificado en grados. Introduce variabilidad en las im√°genes.

**width_shift_range = 0.1:** Realiza un desplazamiento horizontal aleatorio a las im√°genes dentro del rango especificado. En este caso utilizamos 0.1 para que los desechos no salgan demasiado de la imagen.

**height_shift_range = 0.1:** Realiza un desplazamiento vertical aleatorio a las im√°genes dentro del rango especificado. En este caso utilizamos 0.1 para que los desechos no salgan demasiado de la imagen.

**zoom_range = 0.05:** Aplica un zoom aleatorio a las im√°genes dentro del rango especificado. Estamos utilizando 0.05 para crear im√°genes variadas que no modifiquen demasiado la imagen original.

**horizontal_flip = True:** Voltea horizontalmente aleatoriamente las im√°genes. Agrega variabilidad al conjunto de datos al reflejar las im√°genes horizontalmente.

**fill_mode='reflect':** Especifica c√≥mo rellenar los p√≠xeles que pueden quedar vac√≠os despu√©s de aplicar transformaciones. Estamos utilizando reflect para rellenar con valores reflejados los p√≠xeles que quedan vac√≠os para mantener la integridad visual de las im√°genes.

Este set de datos se utiliza para generar im√°genes significativas para el modelo. Se prob√≥ a utilizar diferentes desplazamientos horizontales y verticales, zoom y fill mode, por ejemplo, *nearest*, sin embargo, los valores actuales fueron seleccionados porque no distorsionan demasiado las im√°genes, siendo generadas im√°genes de mejor calidad.

- **Hacer el preprocesado pertinente de los datos.**

En este caso, el escalado (normalizaci√≥n de los valores de los pixeles) de los datos se realiz√≥ como parte del preprocesamiento para los conjuntos de entrenamiento y validaci√≥n.

- **Seleccionar un modelo respaldado por un paper del estado del arte.**

Se realiz√≥ la implementaci√≥n de una Red Neuronal Convolucional (CNN), inspirada en la investigaci√≥n presentada en el art√≠culo "Deep Convolutional Neural Network with TensorFlow and Keras to Classify Skin Cancer Images". Esta elecci√≥n se fundamenta en la robustez y eficacia demostrada por el modelo propuesto, que utiliza t√©cnicas avanzadas de aprendizaje profundo para la clasificaci√≥n precisa de im√°genes de c√°ncer de piel.

Una CNN es un tipo de red neuronal artificial dise√±ada espec√≠ficamente para el procesamiento de im√°genes. Se compone de m√∫ltiples capas, incluyendo capas de convoluci√≥n, activaci√≥n y pooling. La capa de convoluci√≥n resulta fundamental para la CNN, ya que aplica filtros a la imagen de entrada para detectar caracter√≠sticas como bordes, formas y texturas, siendo espec√≠ficamente √∫til para el contexto de este proyecto. La capa de pooling reduce la dimensionalidad de las caracter√≠sticas extra√≠das, lo que ayuda a mejorar la eficiencia computacional y a evitar el sobreajuste.

La adaptaci√≥n de esta arquitectura en el proyecto fue una pieza clave en el inicio del desarrollo, sin embargo, no se utiliza en el modelo final el modelo propuesto por el paper debido a que la CNN del paper era demasiado compleja, siendo este punto justificado debido a que se trata de un modelo de clasificaci√≥n de c√°ncer de piel. Pero para el caso de clasificaci√≥n de residuos, result√≥ demasiado contraproducente, consum√≠a demasiados recursos (epochs de alrededor de 10 minutos cada uno), y despu√©s de experimentar con 5 epochs, el modelo √∫nicamente logr√≥ un accuracy no mayor al 20%.

Se realizaron diversos ajustes, entre ellos, se experiment√≥ con ajustes en el modelo que crearon demasiado overfitting, debido a que la accuracy del conjunto train que se obtuvo fue alta, pero la accuracy del conjunto de validaci√≥n no se aceraba para nada, siendo algunos casos, por ejemplo, un 75% de accuracy, y un 30% de val_accuracy.

Adicionalmente, para efectos pr√°cticos se modific√≥ el dataset, reduciendo las clases de 9 a solamente 5 (Cardboard & Paper, Food Organics, Glass, Metal y Plastic).

El modelo final consta de varias capas que se organizan secuencialmente utilizando la clase Sequential de Keras. A continuaci√≥n se detalla cada capa y su funci√≥n:

**Capa de Convoluci√≥n (Conv2D):** Realiza la convoluci√≥n de los filtros sobre la imagen de entrada para extraer caracter√≠sticas como bordes, texturas y patrones visuales.

Filtrado: 16 filtros.
Tama√±o del kernel: 3x3.
Funci√≥n de activaci√≥n: ReLU.
Tama√±o de entrada: (150, 150, 3). El tama√±o establecido previamente cuando se cargaron los conjuntos.

**Capa de pooling (MaxPooling2D):** Reduce la dimensionalidad de las caracter√≠sticas extra√≠das por la capa de convoluci√≥n, conservando las caracter√≠sticas m√°s relevantes.

Tama√±o de la ventana de pooling: 2x2.

**Segunda Capa de Convoluci√≥n (Conv2D):** Similar a la primera capa, pero con 32 filtros en lugar de 16.

**MaxPooling (MaxPooling2D):** Se utiliza otra capa de pooling de 2x2 para capturar caracter√≠sticas m√°s complejas y abstractas de la imagen.

**Capa de Aplanado (Flatten):** Convierte las caracter√≠sticas 2D obtenidas de las capas convolucionales y de pooling en un vector unidimensional, que se utilizar√° como entrada para las capas completamente conectadas.

**Capas Densas (Dense):** Realizan la clasificaci√≥n final basada en las caracter√≠sticas extra√≠das por las capas convolucionales y de pooling.

Dos capas densas con 32 y 5 neuronas respectivamente.
Funci√≥n de activaci√≥n ReLU en la primera capa densa y funci√≥n de activaci√≥n Softmax en la √∫ltima capa densa para la clasificaci√≥n multiclase.

**Capa de Normalizaci√≥n por Lotes (BatchNormalization):** Normaliza las activaciones de la capa anterior, lo que ayuda a acelerar el entrenamiento y mejorar la estabilidad del modelo.

El modelo se compila utilizando el optimizador Adam, que adapta la tasa de aprendizaje de forma adaptativa. La funci√≥n de p√©rdida se establece como categorical_crossentropy, adecuada para problemas de clasificaci√≥n multiclase, en este caso 5. La m√©trica de evaluaci√≥n se establece en precisi√≥n (accuracy) para monitorear el rendimiento del modelo durante el entrenamiento.

- **Implementar el modelo usando un framework seleccionado.**

Para implementar el modelo, se seleccion√≥ el framework TensorFlow de Google, una de las bibliotecas m√°s populares y utilizadas para el desarrollo de modelos de aprendizaje autom√°tico y redes neuronales, lo que facilita el desarrollo del modelo de clasificaci√≥n.

- **Seleccionar m√©tricas adecuadas respaldadas por un paper del estado del arte.**

De acuerdo con los art√≠culos consultados, las m√©tricas para evaluar el rendimiento del modelo incluyen:

**Precisi√≥n (accuracy):** Mide la proporci√≥n de predicciones correctas sobre el total de predicciones. Fundamental para problemas de clasificaci√≥n.

**P√©rdida (loss):** La funci√≥n de p√©rdida utilizada es categorical_crossentropy, que es adecuada para problemas de clasificaci√≥n multiclase.

- **Reportar resultados obtenidos e interpretarlos.**

Despu√©s de entrenar el modelo con 10 epochs, los resultados obtenidos se evaluaron en t√©rminos de precisi√≥n y p√©rdida en los conjuntos de entrenamiento y validaci√≥n. Adem√°s, se incluye una matriz de confusi√≥n.

![](https://github.com/saidortigoza/MODULO2-TC3002B/blob/main/img/accuray_loss_graphs.png)

La precisi√≥n de train muestra una tendencia alcista, llegando a m√°s del 70%. La precisi√≥n de validation tambi√©n mejora inicialmente y muestra una tendencia alcista, alcanzando un valor m√°ximo de casi 70%, pero luego muestra cierta variabilidad con una ligera disminuci√≥n al final.

La p√©rdida de train disminuye de manera constante a lo largo de las √©pocas, lo cual es una se√±al de que el modelo est√° aprendiendo. La p√©rdida de validation inicialmente disminuye, pero luego muestra cierta variabilidad, con picos en varias epochs antes de volver a disminuir hacia el final.

No parece haber indicios de overfitting severo, ya que las curvas de p√©rdida de entrenamiento y validaci√≥n no se est√°n separando dr√°sticamente, y ambas muestran tendencia al alza. Sin embargo, la variabilidad en la precisi√≥n y p√©rdida de validation sugiere que el modelo podr√≠a beneficiarse de ajustes.

Seg√∫n el comportamiento del modelo, no parece haber underfitting. La precisi√≥n de ambos conjuntos es razonablemente alta.

Sin embargo, las curvas no son perfectamente paralelas y muestran mucha variabilidad en el conjunto de validation, lo que sugiere mejoras. Por lo que el modelo muestra un ligero overfitting.

Adicionalmente, como parte de la evaluaci√≥n se incluye una matriz de confusi√≥n. Incluir una matriz de confusi√≥n como parte de la evaluaci√≥n es fundamental porque ofrece una visi√≥n detallada del rendimiento del modelo en cada clase individual.

![](https://github.com/saidortigoza/MODULO2-TC3002B/blob/main/img/confusion_matrix.png)

Las etiquetas corresponden a lo siguiente:
0: Cardboard & Paper
1: Food Organics
2: Glass
3: Metal
4: Plastic

Los valores de la diagonal corresponden con los valores estimados de forma correcta por el modelo, podemos observar que la mayor√≠a de las clases tienen predicciones aceptables, con exepci√≥n de la clase plastic, la cual tiene much√≠simas predicciones como si fuera cardboard & paper. Esto sugiere que el dataset tambi√©n puede mejorar, existen entre las im√°genes revistas, envases de cart√≥n, hojas blancas, que el modelo confundi√≥ con pl√°stico blanco, como por ejemplo, frascos de pastillas o tapas.

![](https://github.com/saidortigoza/MODULO2-TC3002B/blob/main/img/predictions.png)

## Referencias

- UCI Machine Learning Repository. (2023). Uci.edu. https://archive.ics.uci.edu/dataset/908/realwaste

- Lee, H., Lee, N., & Lee, S. (2022). A Method of Deep Learning Model Optimization for Image Classification on Edge Device. Sensors, 22(19), 7344. https://doi.org/10.3390/s22197344

- Nasir, Israa & Al-Talib, Ghaidaa. (2023). Waste Classification Using Artificial Intelligence Techniques:Literature Review. Technium: Romanian Journal of Applied Sciences and Technology. 5. 49-59. 10.47577/technium.v5i.8345.

- Houssam Benbrahim, Hana√¢ Hachimi, & Amine, A. (2020). Deep Convolutional Neural Network with TensorFlow and Keras to Classify Skin Cancer Images. Scalable Computing. Practice and Experience, 21(3), 379‚Äì390. https://doi.org/10.12694/scpe.v21i3.1725

## Licencia

Este proyecto est√° licenciado bajo la Licencia MIT. Consulta el archivo LICENSE para m√°s detalles.

## Contacto

Para preguntas o comentarios, puedes contactar al autor en saidortigoza@gmail.com.
